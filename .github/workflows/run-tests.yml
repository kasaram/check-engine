name: Tests
on: 
  push:
    branches:
      - main

  pull_request:
    branches:
    - main

jobs:
  pytest:
    name: Run pytest
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@master
    - uses: wei/wget@v1
      name: Download JDK
      with:
        args: -c --header "Cookie:oraclelicense=accept-securebackup-cookie" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz
    - uses: actions/setup-java@v1
      name: Install JDK
      with:
        java-version: 1.8
        jdkFile: jdk-8u131-linux-x64.tar.gz
    - name: Install Spark
      run: |
        mkdir -p /opt/spark
        cd /opt/spark
        wget -O /opt/spark/spark-3.0.0-bin-hadoop2.7.tgz http://ftp.man.poznan.pl/apache/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz
        tar xf spark-3.0.0-bin-hadoop2.7.tgz
    - uses: abatilo/actions-poetry@v1.5.0
      name: Disable virtualenv
      with:
        python_version: 3.8.0
        poetry_version: 1.0
        working_directory: ./correct-horse-lib
        args: config virtualenvs.create false
    - uses: abatilo/actions-poetry@v1.5.0
      name: Download Python dependencies
      with:
        python_version: 3.8.0
        poetry_version: 1.0
        working_directory: ./correct-horse-lib
        args: install
    - run: /root/.pyenv/versions/3.8.0/bin/python3.8 -m pytest -s --cov=correct-horse --cov-branch --cov-fail-under=80 tests/
      env:
        SPARK_HOME: /opt/spark/spark-3.0.0-bin-hadoop2.7
        
